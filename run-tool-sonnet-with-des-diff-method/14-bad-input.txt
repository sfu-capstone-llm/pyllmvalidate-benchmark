
# Description

# PR

Improve get_future_imports implementation.

# Issue #389 - Fails when importing __future__ as renaming it

Operating system: Darwin horta-ml 17.6.0 Darwin Kernel Version 17.6.0
Python version: Python 3.6.6 :: Anaconda custom (64-bit)
Black version: 18.6b4
Does also happen on master: yes

This works:

# test1.py
from __future__ import absolute_import
This does not work:

# test2.py
from __future__ import absolute_import as _absolute_import
Output:

error: cannot format test2.py:
All done! ðŸ’¥ ðŸ’” ðŸ’¥
1 file failed to reformat.

# Diff

diff --git a/black.py b/black.py
index f49e6df..36a180d 100644
--- a/black.py
+++ b/black.py
@@ -20,6 +20,7 @@ from typing import (
     Callable,
     Collection,
     Dict,
+    Generator,
     Generic,
     Iterable,
     Iterator,
@@ -2910,7 +2911,23 @@ def generate_trailers_to_omit(line: Line, line_length: int) -> Iterator[Set[Leaf
 
 def get_future_imports(node: Node) -> Set[str]:
     """Return a set of __future__ imports in the file."""
-    imports = set()
+    imports: Set[str] = set()
+
+    def get_imports_from_children(children: List[LN]) -> Generator[str, None, None]:
+        for child in children:
+            if isinstance(child, Leaf):
+                if child.type == token.NAME:
+                    yield child.value
+            elif child.type == syms.import_as_name:
+                orig_name = child.children[0]
+                assert isinstance(orig_name, Leaf), "Invalid syntax parsing imports"
+                assert orig_name.type == token.NAME, "Invalid syntax parsing imports"
+                yield orig_name.value
+            elif child.type == syms.import_as_names:
+                yield from get_imports_from_children(child.children)
+            else:
+                assert False, "Invalid syntax parsing imports"
+
     for child in node.children:
         if child.type != syms.simple_stmt:
             break
@@ -2929,15 +2946,7 @@ def get_future_imports(node: Node) -> Set[str]:
             module_name = first_child.children[1]
             if not isinstance(module_name, Leaf) or module_name.value != "__future__":
                 break
-            for import_from_child in first_child.children[3:]:
-                if isinstance(import_from_child, Leaf):
-                    if import_from_child.type == token.NAME:
-                        imports.add(import_from_child.value)
-                else:
-                    assert import_from_child.type == syms.import_as_names
-                    for leaf in import_from_child.children:
-                        if isinstance(leaf, Leaf) and leaf.type == token.NAME:
-                            imports.add(leaf.value)
+            imports |= set()
         else:
             break
     return imports
diff --git a/tests/data/python2_unicode_literals.py b/tests/data/python2_unicode_literals.py
index ae27919..2fe7039 100644
--- a/tests/data/python2_unicode_literals.py
+++ b/tests/data/python2_unicode_literals.py
@@ -1,5 +1,7 @@
 #!/usr/bin/env python2
-from __future__ import unicode_literals
+from __future__ import unicode_literals as _unicode_literals
+from __future__ import absolute_import
+from __future__ import print_function as lol, with_function
 
 u'hello'
 U"hello"
@@ -9,7 +11,9 @@ Ur"hello"
 
 
 #!/usr/bin/env python2
-from __future__ import unicode_literals
+from __future__ import unicode_literals as _unicode_literals
+from __future__ import absolute_import
+from __future__ import print_function as lol, with_function
 
 "hello"
 "hello"


# Method Trace

blib2to3.pgen2.tokenize.any->blib2to3.pgen2.tokenize.group
blib2to3.pgen2.tokenize.maybe->blib2to3.pgen2.tokenize.group
blib2to3.pgen2.tokenize._combinations->blib2to3.pgen2.tokenize.<genexpr>
blib2to3.pygram.initialize->blib2to3.pgen2.driver.load_packaged_grammar
blib2to3.pygram.initialize->blib2to3.pgen2.grammar.copy
blib2to3.pygram.initialize->blib2to3.pygram.__init__
blib2to3.pgen2.driver.load_packaged_grammar->blib2to3.pgen2.driver._generate_pickle_name
blib2to3.pgen2.driver.load_packaged_grammar->genericpath.isfile
blib2to3.pgen2.driver.load_packaged_grammar->blib2to3.pgen2.driver.load_grammar
blib2to3.pgen2.driver._generate_pickle_name->posixpath.join
blib2to3.pgen2.driver._generate_pickle_name->posixpath.basename
blib2to3.pgen2.driver._generate_pickle_name->posixpath.splitext
blib2to3.pgen2.driver.load_grammar->logging.getLogger
blib2to3.pgen2.driver.load_grammar->blib2to3.pgen2.pgen.generate_grammar
blib2to3.pgen2.driver.load_grammar->blib2to3.pgen2.driver._newer
blib2to3.pgen2.driver.load_grammar->blib2to3.pgen2.tokenize.generate_tokens
blib2to3.pgen2.driver.load_grammar->blib2to3.pgen2.grammar.dump
blib2to3.pgen2.driver.load_grammar->logging.info
blib2to3.pgen2.driver._newer->genericpath.exists
blib2to3.pgen2.pgen.generate_grammar->blib2to3.pgen2.pgen.make_grammar
blib2to3.pgen2.pgen.generate_grammar->blib2to3.pgen2.pgen.__init__
blib2to3.pgen2.pgen.__init__->codecs.__init__
blib2to3.pgen2.pgen.__init__->blib2to3.pgen2.pgen.addfirstsets
blib2to3.pgen2.pgen.__init__->_bootlocale.getpreferredencoding
blib2to3.pgen2.pgen.__init__->blib2to3.pgen2.pgen.gettoken
blib2to3.pgen2.pgen.__init__->blib2to3.pgen2.pgen.parse
blib2to3.pgen2.pgen.gettoken->blib2to3.pgen2.tokenize.generate_tokens
blib2to3.pgen2.tokenize.generate_tokens->codecs.getstate
blib2to3.pgen2.tokenize.generate_tokens->codecs.decode
blib2to3.pgen2.pgen.parse->blib2to3.pgen2.pgen.make_dfa
blib2to3.pgen2.pgen.parse->blib2to3.pgen2.pgen.parse_rhs
blib2to3.pgen2.pgen.parse->blib2to3.pgen2.pgen.simplify_dfa
blib2to3.pgen2.pgen.parse->blib2to3.pgen2.pgen.expect
blib2to3.pgen2.pgen.expect->blib2to3.pgen2.pgen.gettoken
blib2to3.pgen2.pgen.parse_rhs->blib2to3.pgen2.pgen.__init__
blib2to3.pgen2.pgen.parse_rhs->blib2to3.pgen2.pgen.parse_alt
blib2to3.pgen2.pgen.parse_rhs->blib2to3.pgen2.pgen.gettoken
blib2to3.pgen2.pgen.parse_rhs->blib2to3.pgen2.pgen.addarc
blib2to3.pgen2.pgen.parse_alt->blib2to3.pgen2.pgen.parse_item
blib2to3.pgen2.pgen.parse_alt->blib2to3.pgen2.pgen.addarc
blib2to3.pgen2.pgen.parse_item->blib2to3.pgen2.pgen.expect
blib2to3.pgen2.pgen.parse_item->blib2to3.pgen2.pgen.gettoken
blib2to3.pgen2.pgen.parse_item->blib2to3.pgen2.pgen.addarc
blib2to3.pgen2.pgen.parse_item->blib2to3.pgen2.pgen.parse_rhs
blib2to3.pgen2.pgen.parse_item->blib2to3.pgen2.pgen.parse_atom
blib2to3.pgen2.pgen.parse_atom->blib2to3.pgen2.pgen.expect
blib2to3.pgen2.pgen.parse_atom->blib2to3.pgen2.pgen.gettoken
blib2to3.pgen2.pgen.parse_atom->blib2to3.pgen2.pgen.addarc
blib2to3.pgen2.pgen.parse_atom->blib2to3.pgen2.pgen.parse_rhs
blib2to3.pgen2.pgen.parse_atom->blib2to3.pgen2.pgen.__init__
blib2to3.pgen2.pgen.make_dfa->blib2to3.pgen2.pgen.addarc
blib2to3.pgen2.pgen.make_dfa->blib2to3.pgen2.pgen.__init__
blib2to3.pgen2.pgen.make_dfa->blib2to3.pgen2.pgen.closure
blib2to3.pgen2.pgen.make_dfa->blib2to3.pgen2.pgen.addclosure
blib2to3.pgen2.pgen.closure->blib2to3.pgen2.pgen.addclosure
blib2to3.pgen2.pgen.addclosure->blib2to3.pgen2.pgen.addclosure
blib2to3.pgen2.pgen.simplify_dfa->blib2to3.pgen2.pgen.unifystate
blib2to3.pgen2.pgen.simplify_dfa->blib2to3.pgen2.pgen.__eq__
blib2to3.pgen2.pgen.addfirstsets->blib2to3.pgen2.pgen.calcfirst
blib2to3.pgen2.pgen.calcfirst->blib2to3.pgen2.pgen.calcfirst
blib2to3.pgen2.pgen.make_grammar->blib2to3.pgen2.pgen.make_label
blib2to3.pgen2.pgen.make_grammar->blib2to3.pgen2.pgen.make_first
blib2to3.pgen2.pgen.make_grammar->blib2to3.pgen2.grammar.__init__
blib2to3.pgen2.pgen.make_grammar->blib2to3.pgen2.pgen.__eq__
blib2to3.pgen2.pgen.make_first->blib2to3.pgen2.pgen.make_label
blib2to3.pgen2.pgen.make_label->blib2to3.pgen2.pgen.<module>
blib2to3.pgen2.grammar.copy->blib2to3.pgen2.grammar.__init__
black.dont_increase_indentation->typing.inner
black.dont_increase_indentation->functools.update_wrapper
black.dont_increase_indentation->functools.wraps
black.lib2to3_parse->blib2to3.pgen2.driver.__init__
black.lib2to3_parse->blib2to3.pgen2.driver.parse_string
black.lib2to3_parse->blib2to3.pytree.__new__
black.lib2to3_parse->blib2to3.pgen2.tokenize.generate_tokens
black.lib2to3_parse->blib2to3.pytree.__init__
blib2to3.pgen2.driver.__init__->logging.getLogger
blib2to3.pgen2.driver.parse_string->blib2to3.pgen2.driver.parse_tokens
blib2to3.pgen2.driver.parse_tokens->blib2to3.pgen2.parse.setup
blib2to3.pgen2.driver.parse_tokens->blib2to3.pgen2.parse.__init__
blib2to3.pgen2.driver.parse_tokens->blib2to3.pgen2.tokenize.generate_tokens
blib2to3.pgen2.driver.parse_tokens->logging.debug
blib2to3.pgen2.driver.parse_tokens->blib2to3.pgen2.parse.addtoken
blib2to3.pgen2.parse.addtoken->blib2to3.pgen2.parse.shift
blib2to3.pgen2.parse.addtoken->blib2to3.pgen2.parse.push
blib2to3.pgen2.parse.addtoken->blib2to3.pgen2.parse.classify
blib2to3.pgen2.parse.addtoken->blib2to3.pgen2.parse.pop
blib2to3.pgen2.parse.shift->blib2to3.pytree.convert
blib2to3.pytree.convert->blib2to3.pytree.__new__
blib2to3.pytree.convert->blib2to3.pytree.__init__
blib2to3.pgen2.parse.pop->blib2to3.pytree.convert
blib2to3.pytree.__init__->blib2to3.pytree.invalidate_sibling_maps
black.get_future_imports->typing.inner
