
# Description

# PR

Add support for always tokenizing async/await as keywords
Fixes #593

I looked into this bug with @ambv and @carljm, and we reached the
conclusion was that it's not possible for the tokenizer to determine if
async/await is a keyword inside all possible generators without breaking
the grammar for older versions of Python.

Instead, we introduce a new tokenizer mode for Python 3.7+ that will
cause all async/await instances to get parsed as a reserved keyword,
which should fix async/await inside generators.

# Issue #593 - Black can't parse new Python 3.7 async generator syntax

Operating system: Linux but unlikely to be OS specific
Python version: 3.7.1
Black version: 18.9b0
Does also happen on master: Yes (as of 32eed7d)

The following code (extracted from test_asyncgen.py in CPython) is currently not handled by black:

def make_arange(n):
    # This syntax is legal starting with Python 3.7
    return (i * 2 for i in range(n) if await wrap(i))
Running black on it results in:

error: cannot format test_asyncgen.py: Cannot parse: 3:45:     return (i * 2 for i in range(n) if await wrap(i))
All done! ðŸ’¥ ðŸ’” ðŸ’¥
1 file failed to reformat.
As per the comment, this is new Python 3.7 syntax, so presumably "just" a case of needing to update the parser to reflect the grammar change.

# Diff

diff --git a/black.py b/black.py
index c96d205..5e0f0a7 100644
--- a/black.py
+++ b/black.py
@@ -48,6 +48,7 @@ from blib2to3 import pygram, pytree
 from blib2to3.pgen2 import driver, token
 from blib2to3.pgen2.grammar import Grammar
 from blib2to3.pgen2.parse import ParseError
+from blib2to3.pgen2.tokenize import TokenizerConfig
 
 
 __version__ = "19.3b0"
@@ -136,19 +137,28 @@ class Feature(Enum):
     NUMERIC_UNDERSCORES = 3
     TRAILING_COMMA_IN_CALL = 4
     TRAILING_COMMA_IN_DEF = 5
+    # The following two feature-flags are mutually exclusive, and exactly one should be
+    # set for every version of python.
+    ASYNC_IS_VALID_IDENTIFIER = 6
+    ASYNC_IS_RESERVED_KEYWORD = 7
 
 
 VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
-    TargetVersion.PY27: set(),
-    TargetVersion.PY33: {Feature.UNICODE_LITERALS},
-    TargetVersion.PY34: {Feature.UNICODE_LITERALS},
-    TargetVersion.PY35: {Feature.UNICODE_LITERALS, Feature.TRAILING_COMMA_IN_CALL},
+    TargetVersion.PY27: {Feature.ASYNC_IS_VALID_IDENTIFIER},
+    TargetVersion.PY33: {Feature.UNICODE_LITERALS, Feature.ASYNC_IS_VALID_IDENTIFIER},
+    TargetVersion.PY34: {Feature.UNICODE_LITERALS, Feature.ASYNC_IS_VALID_IDENTIFIER},
+    TargetVersion.PY35: {
+        Feature.UNICODE_LITERALS,
+        Feature.TRAILING_COMMA_IN_CALL,
+        Feature.ASYNC_IS_VALID_IDENTIFIER,
+    },
     TargetVersion.PY36: {
         Feature.UNICODE_LITERALS,
         Feature.F_STRINGS,
         Feature.NUMERIC_UNDERSCORES,
         Feature.TRAILING_COMMA_IN_CALL,
         Feature.TRAILING_COMMA_IN_DEF,
+        Feature.ASYNC_IS_VALID_IDENTIFIER,
     },
     TargetVersion.PY37: {
         Feature.UNICODE_LITERALS,
@@ -156,6 +166,7 @@ VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
         Feature.NUMERIC_UNDERSCORES,
         Feature.TRAILING_COMMA_IN_CALL,
         Feature.TRAILING_COMMA_IN_DEF,
+        Feature.ASYNC_IS_RESERVED_KEYWORD,
     },
     TargetVersion.PY38: {
         Feature.UNICODE_LITERALS,
@@ -163,6 +174,7 @@ VERSION_TO_FEATURES: Dict[TargetVersion, Set[Feature]] = {
         Feature.NUMERIC_UNDERSCORES,
         Feature.TRAILING_COMMA_IN_CALL,
         Feature.TRAILING_COMMA_IN_DEF,
+        Feature.ASYNC_IS_RESERVED_KEYWORD,
     },
 }
 
@@ -748,20 +760,62 @@ def decode_bytes(src: bytes) -> Tuple[FileContent, Encoding, NewLine]:
         return tiow.read(), encoding, newline
 
 
-def get_grammars(target_versions: Set[TargetVersion]) -> List[Grammar]:
+@dataclass(frozen=True)
+class ParserConfig:
+    grammar: Grammar
+    tokenizer_config: TokenizerConfig = TokenizerConfig()
+
+
+def get_parser_configs(target_versions: Set[TargetVersion]) -> List[ParserConfig]:
     if not target_versions:
         # No target_version specified, so try all grammars.
         return [
-            pygram.python_grammar_no_print_statement_no_exec_statement,
-            pygram.python_grammar_no_print_statement,
-            pygram.python_grammar,
+            # Python 3.7+
+            ParserConfig(
+                pygram.python_grammar_no_print_statement_no_exec_statement,
+                TokenizerConfig(async_is_reserved_keyword=True),
+            ),
+            # Python 3.0-3.6
+            ParserConfig(
+                pygram.python_grammar_no_print_statement_no_exec_statement,
+                TokenizerConfig(async_is_reserved_keyword=False),
+            ),
+            # Python 2.7 with future print_function import
+            ParserConfig(pygram.python_grammar_no_print_statement),
+            # Python 2.7
+            ParserConfig(pygram.python_grammar),
         ]
     elif all(version.is_python2() for version in target_versions):
         # Python 2-only code, so try Python 2 grammars.
-        return [pygram.python_grammar_no_print_statement, pygram.python_grammar]
+        return [
+            # Python 2.7 with future print_function import
+            ParserConfig(pygram.python_grammar_no_print_statement),
+            # Python 2.7
+            ParserConfig(pygram.python_grammar),
+        ]
     else:
         # Python 3-compatible code, so only try Python 3 grammar.
-        return [pygram.python_grammar_no_print_statement_no_exec_statement]
+        configs = []
+        # If we have to parse both, try to parse async as a keyword first
+        if not supports_feature(target_versions, Feature.ASYNC_IS_VALID_IDENTIFIER):
+            # Python 3.7+
+            configs.append(
+                ParserConfig(
+                    pygram.python_grammar_no_print_statement_no_exec_statement,
+                    TokenizerConfig(async_is_reserved_keyword=True),
+                )
+            )
+        if not supports_feature(target_versions, Feature.ASYNC_IS_RESERVED_KEYWORD):
+            # Python 3.0-3.6
+            configs.append(
+                ParserConfig(
+                    pygram.python_grammar_no_print_statement_no_exec_statement,
+                    TokenizerConfig(async_is_reserved_keyword=False),
+                )
+            )
+        # At least one of the above branches must have been taken, because every Python
+        # version has exactly one of the two 'ASYNC_IS_*' flags
+        return configs
 
 
 def lib2to3_parse(src_txt: str, target_versions: Iterable[TargetVersion] = ()) -> Node:
@@ -769,8 +823,12 @@ def lib2to3_parse(src_txt: str, target_versions: Iterable[TargetVersion] = ()) -
     if src_txt[-1:] != "\n":
         src_txt += "\n"
 
-    for grammar in get_grammars(set(target_versions)):
-        drv = driver.Driver(grammar, pytree.convert)
+    for parser_config in get_parser_configs(set(target_versions)):
+        drv = driver.Driver(
+            parser_config.grammar,
+            pytree.convert,
+            tokenizer_config=parser_config.tokenizer_config,
+        )
         try:
             result = drv.parse_string(src_txt, True)
             break
diff --git a/blib2to3/pgen2/driver.py b/blib2to3/pgen2/driver.py
index 63b60bb..e681b52 100644
--- a/blib2to3/pgen2/driver.py
+++ b/blib2to3/pgen2/driver.py
@@ -29,12 +29,19 @@ from . import grammar, parse, token, tokenize, pgen
 
 class Driver(object):
 
-    def __init__(self, grammar, convert=None, logger=None):
+    def __init__(
+        self,
+        grammar,
+        convert=None,
+        logger=None,
+        tokenizer_config=tokenize.TokenizerConfig(),
+    ):
         self.grammar = grammar
         if logger is None:
             logger = logging.getLogger(__name__)
         self.logger = logger
         self.convert = convert
+        self.tokenizer_config = tokenizer_config
 
     def parse_tokens(self, tokens, debug=False):
         """Parse a series of tokens and return the syntax tree."""
@@ -97,7 +104,7 @@ class Driver(object):
 
     def parse_stream_raw(self, stream, debug=False):
         """Parse a stream and return the syntax tree."""
-        tokens = tokenize.generate_tokens(stream.readline)
+        tokens = tokenize.generate_tokens(stream.readline, config=self.tokenizer_config)
         return self.parse_tokens(tokens, debug)
 
     def parse_stream(self, stream, debug=False):
@@ -111,7 +118,10 @@ class Driver(object):
 
     def parse_string(self, text, debug=False):
         """Parse a string and return the syntax tree."""
-        tokens = tokenize.generate_tokens(io.StringIO(text).readline)
+        tokens = tokenize.generate_tokens(
+            io.StringIO(text).readline,
+            config=self.tokenizer_config,
+        )
         return self.parse_tokens(tokens, debug)
 
     def _partially_consume_prefix(self, prefix, column):
diff --git a/blib2to3/pgen2/tokenize.py b/blib2to3/pgen2/tokenize.py
index 1f51ff6..43e1d59 100644
--- a/blib2to3/pgen2/tokenize.py
+++ b/blib2to3/pgen2/tokenize.py
@@ -31,6 +31,7 @@ __credits__ = \
 
 import re
 from codecs import BOM_UTF8, lookup
+from attr import dataclass
 from blib2to3.pgen2.token import *
 
 from . import token
@@ -137,6 +138,10 @@ single_quoted = (
 
 tabsize = 8
 
+@dataclass(frozen=True)
+class TokenizerConfig:
+    async_is_reserved_keyword: bool = False
+
 class TokenError(Exception): pass
 
 class StopTokenizing(Exception): pass
@@ -334,7 +339,7 @@ def untokenize(iterable):
     ut = Untokenizer()
     return ut.untokenize(iterable)
 
-def generate_tokens(readline):
+def generate_tokens(readline, config: TokenizerConfig = TokenizerConfig()):
     """
     The generate_tokens() generator requires one argument, readline, which
     must be a callable object which provides the same interface as the
@@ -356,6 +361,9 @@ def generate_tokens(readline):
     contline = None
     indents = [0]
 
+    # If we know we're parsing 3.7+, we can unconditionally parse `async` and
+    # `await` as keywords.
+    async_is_reserved_keyword = config.async_is_reserved_keyword
     # 'stashed' and 'async_*' are used for async/await parsing
     stashed = None
     async_def = False
@@ -506,7 +514,7 @@ def generate_tokens(readline):
                         yield (STRING, token, spos, epos, line)
                 elif initial.isidentifier():               # ordinary name
                     if token in ('async', 'await'):
-                        if async_def:
+                        if async_is_reserved_keyword and async_def:
                             yield (ASYNC if token == 'async' else AWAIT,
                                    token, spos, epos, line)
                             continue
diff --git a/tests/data/python37.py b/tests/data/python37.py
index 9781ff6..4401b7b 100644
--- a/tests/data/python37.py
+++ b/tests/data/python37.py
@@ -14,6 +14,14 @@ async def func():
                 self.async_inc, arange(8), batch_size=3
             )
         ]
+
+def awaited_generator_value(n):
+    return (await awaitable for awaitable in awaitable_list)
+
+def make_arange(n):
+    return (i * 2 for i in range(n) if await wrap(i))
+
+
 # output
 
 
@@ -39,3 +47,11 @@ async def func():
                 self.async_inc, arange(8), batch_size=3
             )
         ]
+
+
+def awaited_generator_value(n):
+    return (await awaitable for awaitable in awaitable_list)
+
+
+def make_arange(n):
+    return (i * 2 for i in range(n) if await wrap(i))


# Method Trace

blib2to3.pgen2.tokenize.any->blib2to3.pgen2.tokenize.group
blib2to3.pgen2.tokenize.maybe->blib2to3.pgen2.tokenize.group
blib2to3.pgen2.tokenize._combinations->blib2to3.pgen2.tokenize.<genexpr>
blib2to3.pygram.initialize->blib2to3.pgen2.driver.load_packaged_grammar
blib2to3.pygram.initialize->blib2to3.pgen2.grammar.copy
blib2to3.pygram.initialize->blib2to3.pygram.__init__
blib2to3.pgen2.driver.load_packaged_grammar->blib2to3.pgen2.driver.load_grammar
blib2to3.pgen2.driver.load_packaged_grammar->genericpath.isfile
blib2to3.pgen2.driver.load_packaged_grammar->blib2to3.pgen2.driver._generate_pickle_name
blib2to3.pgen2.driver._generate_pickle_name->posixpath.basename
blib2to3.pgen2.driver._generate_pickle_name->posixpath.join
blib2to3.pgen2.driver._generate_pickle_name->posixpath.splitext
blib2to3.pgen2.driver.load_grammar->blib2to3.pgen2.grammar.load
blib2to3.pgen2.driver.load_grammar->logging.getLogger
blib2to3.pgen2.driver.load_grammar->blib2to3.pgen2.grammar.__init__
blib2to3.pgen2.driver.load_grammar->blib2to3.pgen2.driver._newer
blib2to3.pgen2.driver._newer->genericpath.exists
blib2to3.pgen2.driver._newer->genericpath.getmtime
blib2to3.pgen2.grammar.copy->blib2to3.pgen2.grammar.__init__
black.dont_increase_indentation->typing.inner
black.dont_increase_indentation->functools.wraps
black.dont_increase_indentation->functools.update_wrapper
black.format_str->black.supports_feature
black.format_str->black.__str__
black.format_str->black.normalize_fmt_off
black.format_str->black.lib2to3_parse
black.format_str->enum.__hash__
black.format_str->black.detect_target_versions
black.format_str->typing.__new__
black.format_str->black.maybe_empty_lines
black.format_str->black.get_future_imports
black.format_str->.__init__
black.format_str->black.<setcomp>
black.format_str->black.split_line
black.format_str->black.visit
black.lib2to3_parse->black.get_grammars
black.lib2to3_parse->blib2to3.pgen2.tokenize.generate_tokens
black.lib2to3_parse->blib2to3.pgen2.driver.__init__
black.lib2to3_parse->blib2to3.pgen2.driver.parse_string
blib2to3.pgen2.driver.__init__->logging.getLogger
blib2to3.pgen2.driver.parse_string->blib2to3.pgen2.driver.parse_tokens
blib2to3.pgen2.driver.parse_tokens->blib2to3.pgen2.parse.__init__
blib2to3.pgen2.driver.parse_tokens->blib2to3.pgen2.driver._partially_consume_prefix
blib2to3.pgen2.driver.parse_tokens->blib2to3.pgen2.parse.setup
blib2to3.pgen2.driver.parse_tokens->blib2to3.pgen2.tokenize.generate_tokens
blib2to3.pgen2.driver.parse_tokens->logging.debug
blib2to3.pgen2.driver.parse_tokens->blib2to3.pgen2.parse.addtoken
blib2to3.pgen2.parse.addtoken->blib2to3.pgen2.parse.shift
blib2to3.pgen2.parse.addtoken->blib2to3.pgen2.parse.classify
blib2to3.pgen2.parse.addtoken->blib2to3.pgen2.parse.pop
blib2to3.pgen2.parse.addtoken->blib2to3.pgen2.parse.push
blib2to3.pgen2.parse.shift->blib2to3.pytree.convert
blib2to3.pytree.convert->blib2to3.pytree.__new__
blib2to3.pytree.convert->blib2to3.pytree.__init__
blib2to3.pgen2.parse.pop->blib2to3.pytree.convert
blib2to3.pytree.__init__->blib2to3.pytree.invalidate_sibling_maps
black.get_future_imports->typing.inner
black.detect_target_versions->black.<setcomp>
black.detect_target_versions->enum.__iter__
black.detect_target_versions->black.get_features_used
black.get_features_used->blib2to3.pytree.pre_order
blib2to3.pytree.pre_order->blib2to3.pytree.pre_order
black.normalize_fmt_off->black.convert_one_fmt_off_pair
black.convert_one_fmt_off_pair->blib2to3.pytree.leaves
black.convert_one_fmt_off_pair->black.list_comments
black.convert_one_fmt_off_pair->blib2to3.pytree.prefix
blib2to3.pytree.leaves->blib2to3.pytree.leaves
black.supports_feature->black.<genexpr>
black.visit->black.visit_stmt
black.visit->black.visit_default
black.visit->black.visit_DEDENT
black.visit->black.visit_simple_stmt
black.visit->blib2to3.pytree.type_repr
black.visit->black.visit_ENDMARKER
black.visit->black.visit_async_stmt
black.visit->black.visit_INDENT
black.visit->black.visit_suite
blib2to3.pytree.type_repr->importlib._bootstrap.parent
black.visit_default->black.visit_default
black.visit_default->black.line
black.visit_default->black.generate_comments
black.visit_default->black.append
black.visit_default->black.any_open_brackets
black.visit_default->black.visit
black.visit_default->black.normalize_prefix
black.visit_stmt->black.line
black.visit_stmt->black.normalize_invisible_parens
black.visit_stmt->black.visit
black.normalize_invisible_parens->black.is_one_tuple
black.normalize_invisible_parens->blib2to3.pytree.__new__
black.normalize_invisible_parens->blib2to3.pytree.__init__
black.normalize_invisible_parens->blib2to3.pytree.remove
black.normalize_invisible_parens->blib2to3.pytree.prefix
black.normalize_invisible_parens->blib2to3.pytree.insert_child
blib2to3.pytree.prefix->blib2to3.pytree.changed
blib2to3.pytree.prefix->blib2to3.pytree.prefix
black.line->black.__bool__
black.line->.__init__
black.generate_comments->blib2to3.pytree.__new__
black.generate_comments->blib2to3.pytree.__init__
black.generate_comments->black.list_comments
black.generate_comments->blib2to3.pytree.prefix
black.normalize_prefix->blib2to3.pytree.prefix
blib2to3.pytree.changed->blib2to3.pytree.changed
black.append->black.is_class_paren_empty
black.append->black.maybe_remove_trailing_comma
black.append->black.append_comment
black.append->black.is_complex_subscript
black.append->black.whitespace
black.append->blib2to3.pytree.prefix
black.append->black.mark
black.mark->black.maybe_increment_for_loop_variable
black.mark->black.is_split_after_delimiter
black.mark->black.maybe_decrement_after_lambda_arguments
black.mark->black.maybe_decrement_after_for_loop_variable
black.mark->black.maybe_increment_lambda_arguments
black.mark->black.is_split_before_delimiter
black.is_split_before_delimiter->black.is_vararg
black.is_split_before_delimiter->blib2to3.pytree.prev_sibling
black.is_complex_subscript->black.get_open_lsqb
black.whitespace->blib2to3.pytree.prev_sibling
black.whitespace->black.preceding_leaf
blib2to3.pytree.prev_sibling->blib2to3.pytree.update_sibling_maps
black.preceding_leaf->blib2to3.pytree.prev_sibling
black.is_class_paren_empty->black.__bool__
black.is_class_paren_empty->black.is_class
black.is_class->black.__bool__
black.visit_suite->black.visit_default
black.visit_INDENT->black.visit_default
black.visit_INDENT->black.line
black.maybe_empty_lines->black._maybe_empty_lines
black._maybe_empty_lines->black.is_def
black._maybe_empty_lines->black._maybe_empty_lines_for_class_or_def
black._maybe_empty_lines->black.is_import
black._maybe_empty_lines->black.is_decorator
black._maybe_empty_lines->black.__bool__
black._maybe_empty_lines->black.is_class
black._maybe_empty_lines->blib2to3.pytree.prefix
black.is_decorator->black.__bool__
black._maybe_empty_lines_for_class_or_def->black.is_decorator
black._maybe_empty_lines_for_class_or_def->black.is_comment
black.split_line->black.is_line_short_enough
black.split_line->black.contains_inner_type_comments
black.split_line->black.__str__
black.split_line->black.is_comment
black.__str__->click.termui.style
black.__str__->blib2to3.pytree.__unicode__
black.__str__->black.__bool__
black.__str__->blib2to3.pytree.prefix
blib2to3.pytree.__unicode__->blib2to3.pytree.prefix
black.is_line_short_enough->black.contains_standalone_comments
black.visit_simple_stmt->black.visit_default
black.visit_simple_stmt->black.line
black.visit_DEDENT->black.visit_default
black.visit_DEDENT->black.line
black.is_import->black.is_import
black.is_import->black.__bool__
blib2to3.pytree.remove->blib2to3.pytree.invalidate_sibling_maps
blib2to3.pytree.remove->blib2to3.pytree.changed
blib2to3.pytree.insert_child->blib2to3.pytree.invalidate_sibling_maps
blib2to3.pytree.insert_child->blib2to3.pytree.changed
black.visit_async_stmt->black.line
black.visit_async_stmt->black.visit
black.visit_ENDMARKER->black.visit_default
black.visit_ENDMARKER->black.line
black.assert_stable->black.format_str
black.read_pyproject_toml->toml.decoder.load
black.main->black.find_project_root
black.main->black.__str__
black.main->black.return_code
black.main->pathlib.is_dir
black.main->pathlib.is_file
black.main->enum.__hash__
black.main->black.from_configuration
black.main->pathlib.__hash__
black.main->click.core.exit
black.main->.__init__
black.main->pathlib.__new__
black.main->black.reformat_one
black.main->black.re_compile_maybe_verbose
black.main->click.termui.secho
black.re_compile_maybe_verbose->re.compile
black.find_project_root->pathlib.__truediv__
black.find_project_root->pathlib.is_dir
black.find_project_root->pathlib.is_file
black.find_project_root->collections.abc.__iter__
black.find_project_root->pathlib.parents
black.find_project_root->black.<genexpr>
black.reformat_one->pathlib.is_file
black.reformat_one->black.done
black.reformat_one->pathlib.__hash__
black.reformat_one->black.format_file_in_place
black.reformat_one->tempfile.__del__
black.reformat_one->black.write_cache
black.reformat_one->pathlib.resolve
black.reformat_one->black.read_cache
black.read_cache->pathlib.open
black.read_cache->pathlib.__hash__
black.read_cache->pathlib.exists
black.read_cache->pathlib.__new__
black.read_cache->black.get_cache_file
black.get_cache_file->pathlib.__truediv__
black.get_cache_file->black.get_cache_key
black.get_cache_key->black.<lambda>
black.get_cache_key->black.<genexpr>
black.format_file_in_place->black.format_file_contents
black.format_file_in_place->pathlib.stat
black.format_file_in_place->pathlib.suffix
black.format_file_in_place->black.decode_bytes
black.format_file_in_place->codecs.__init__
black.format_file_in_place->pathlib.__fspath__
black.decode_bytes->tokenize.detect_encoding
black.decode_bytes->codecs.__init__
black.decode_bytes->codecs.decode
black.format_file_contents->black.format_str
black.format_file_contents->black.assert_equivalent
black.format_file_contents->black.assert_stable
black.get_grammars->black.<genexpr>
black.list_comments->black.make_comment
black.list_comments->.__init__
black.append_comment->black.any_open_brackets
black.assert_equivalent->typing.inner
black.assert_equivalent->black._v
black.assert_equivalent->black.parse_ast
black.parse_ast->typed_ast.ast3.parse
black._v->black._v
black.write_cache->pathlib.parent
black.write_cache->tempfile.NamedTemporaryFile
black.write_cache->tempfile.__getattr__
black.write_cache->tempfile.__enter__
black.write_cache->tempfile.func_wrapper
black.write_cache->pathlib.mkdir
black.write_cache->black.<dictcomp>
black.write_cache->pathlib.__fspath__
black.write_cache->pathlib.__str__
black.write_cache->pathlib.__reduce__
black.write_cache->tempfile.__exit__
black.write_cache->black.get_cache_file
black.get_cache_info->pathlib.stat
black.done->pathlib.__str__
black.done->click.termui.secho

# Coverage

Name                  Stmts   Miss  Cover   Missing
---------------------------------------------------
black.py               1928   1036    46%   105, 184, 208-213, 218-219, 226-231, 382-383, 386-394, 402, 404-405, 408-410, 413-415, 422, 429, 431-433, 444, 467-468, 475, 485-486, 497-516, 535-587, 604, 617-635, 648-669, 682, 723, 743, 761, 778-787, 790, 796-797, 834-851, 859-862, 1003, 1015, 1019, 1037, 1044-1048, 1057-1059, 1071-1073, 1134, 1153-1162, 1191, 1200-1201, 1233, 1243-1244, 1256-1259, 1262-1267, 1272-1276, 1287-1330, 1338-1339, 1344-1350, 1354, 1358-1360, 1370-1378, 1394, 1440, 1445, 1457, 1464, 1478, 1483, 1493-1505, 1509, 1549, 1552-1553, 1564-1565, 1567, 1616, 1624-1629, 1653-1655, 1659, 1667-1669, 1720, 1737-1743, 1753, 1759, 1762-1763, 1766-1767, 1774, 1785, 1788, 1797-1798, 1802-1815, 1819-1822, 1829-1839, 1843-1852, 1856, 1859-1864, 1867-1871, 1875-1883, 1888, 1892-1893, 1897-1914, 1917-1926, 1929, 1942-1949, 1954-1957, 1965-1982, 1994, 2010, 2018, 2025, 2028, 2035, 2057, 2060, 2063, 2075, 2087, 2090, 2160-2161, 2164, 2187, 2192, 2226-2269, 2279-2305, 2322-2394, 2411-2417, 2431-2456, 2467-2469, 2481-2541, 2549-2572, 2592-2594, 2622-2628, 2639-2695, 2704-2731, 2736-2740, 2755, 2765, 2769-2773, 2776-2779, 2783-2791, 2826-2861, 2873-2881, 2890-2909, 2914, 2925-2936, 2947-2963, 2977-2986, 2991-2992, 2997-3005, 3010-3017, 3030-3049, 3058-3061, 3067-3081, 3095-3097, 3100-3101, 3108-3120, 3143-3180, 3188-3200, 3205-3222, 3240-3266, 3280, 3285, 3291, 3294-3296, 3319-3323, 3328-3329, 3332-3333, 3347, 3350, 3360-3362, 3377-3378, 3391, 3406, 3410, 3414-3415, 3428-3429, 3443-3444, 3451-3453, 3462-3463, 3475-3479, 3489-3498, 3503-3507, 3514-3516, 3521-3542, 3551, 3560, 3566-3569, 3579-3592, 3601, 3616-3642, 3652-3731, 3745, 3750-3751, 3768-3775, 3787-3788, 3802-3810, 3814-3816, 3820
blackd.py               100     71    29%   42-46, 50-64, 68-121, 125-152, 156-158, 162
tests/__init__.py         0      0   100%
tests/test_black.py    1208    952    21%   36-37, 54, 76, 82-87, 92-102, 109, 145-158, 172-176, 179-187, 191-196, 200-205, 208-217, 220-240, 244-249, 253-257, 261-265, 269-273, 276-287, 290-312, 316-320, 324-333, 337-341, 345-349, 353-357, 361-365, 369-373, 377-381, 385-389, 393-397, 401-405, 409-413, 417-421, 425-429, 433-437, 441-445, 449-454, 458-463, 467-470, 474-478, 482-487, 491-495, 499-503, 513, 522-533, 537-541, 545-549, 553-557, 561-565, 569-573, 577-581, 584-603, 606-694, 701-781, 788-871, 878-900, 903-931, 934-961, 964-981, 988-1005, 1008-1011, 1015-1031, 1034-1045, 1048-1056, 1060-1078, 1081-1088, 1091-1098, 1101-1103, 1106-1113, 1116-1129, 1132-1136, 1140-1153, 1156-1159, 1163-1171, 1174-1176, 1179-1185, 1188-1197, 1200-1215, 1219-1240, 1243-1249, 1252-1267, 1271-1292, 1295-1303, 1306-1319, 1322-1343, 1346-1364, 1367-1368, 1371-1380, 1383-1393, 1396-1397, 1400-1428, 1431-1450, 1453-1465, 1470-1475, 1480-1484, 1489-1494, 1502-1507, 1512-1517, 1522-1541, 1546-1553, 1558-1585, 1590-1595, 1600-1607, 1611-1615, 1619
---------------------------------------------------
TOTAL                  3236   2059    36%
RUN EVERY COMMAND
1
python -m unittest -q tests.test_black.BlackTestCase.test_python37
======================================================================
ERROR: test_python37 (tests.test_black.BlackTestCase)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/unittest/mock.py", line 1325, in patched
    return func(*newargs, **newkeywargs)
  File "/workspace/BugsInPy/framework/bin/temp/black-6/bad/black/tests/test_black.py", line 524, in test_python37
    actual = fs(source)
  File "/workspace/BugsInPy/framework/bin/temp/black-6/bad/black/black.py", line 699, in format_str
    src_node = lib2to3_parse(src_contents.lstrip(), mode.target_versions)
  File "/workspace/BugsInPy/framework/bin/temp/black-6/bad/black/black.py", line 787, in lib2to3_parse
    raise exc from None
black.InvalidInput: Cannot parse: 19:18:     return (await awaitable for awaitable in awaitable_list)

----------------------------------------------------------------------
Ran 1 test in 0.007s

FAILED (errors=1)
Name                  Stmts   Miss  Cover   Missing
---------------------------------------------------
black.py               1928   1578    18%   104-107, 126, 178-191, 195, 206-231, 379-452, 464-486, 497-516, 535-587, 603-636, 648-669, 681-691, 700-731, 740-748, 759-764, 770, 776, 783-784, 789-791, 796-797, 816-820, 824-826, 834-851, 859-862, 1002-1025, 1029, 1037, 1044-1048, 1056-1061, 1065-1075, 1083-1088, 1092-1101, 1105, 1129-1145, 1153-1162, 1167, 1172, 1177, 1182, 1191, 1198-1207, 1220, 1233, 1241-1245, 1248-1269, 1272-1276, 1280-1330, 1334-1350, 1354, 1358-1360, 1366-1378, 1384-1395, 1399, 1423-1427, 1430-1466, 1471-1510, 1534-1540, 1544-1570, 1575-1576, 1583-1590, 1606-1611, 1615-1618, 1622-1634, 1638-1649, 1653-1655, 1659, 1663-1664, 1667-1669, 1673-1693, 1710-1931, 1936-1949, 1954-1957, 1965-1982, 1993-1996, 2007-2092, 2118-2119, 2143-2174, 2185-2193, 2211-2269, 2279-2305, 2322-2394, 2411-2417, 2431-2456, 2467-2469, 2481-2541, 2549-2572, 2577-2580, 2592-2594, 2603-2612, 2622-2628, 2639-2695, 2704-2731, 2736-2740, 2752-2804, 2809-2811, 2819-2865, 2873-2881, 2890-2909, 2914, 2924-2938, 2947-2963, 2974-2986, 2991-2992, 2997-3005, 3010-3017, 3030-3049, 3058-3061, 3067-3081, 3092-3122, 3127-3128, 3143-3180, 3185-3223, 3240-3266, 3279-3296, 3312-3324, 3328-3329, 3332-3333, 3346-3352, 3359-3381, 3385-3391, 3397-3463, 3473-3479, 3489-3498, 3503-3507, 3514-3516, 3521-3542, 3551, 3559-3561, 3566-3569, 3579-3592, 3600-3602, 3616-3642, 3652-3731, 3735, 3743-3753, 3758-3759, 3768-3775, 3780-3788, 3802-3810, 3814-3816, 3820
blackd.py               100     71    29%   42-46, 50-64, 68-121, 125-152, 156-158, 162
tests/__init__.py         0      0   100%
tests/test_black.py    1208    978    19%   36-37, 54, 76, 82-87, 92-102, 109, 120-124, 128-136, 143-159, 164-168, 172-176, 179-187, 191-196, 200-205, 208-217, 220-240, 244-249, 253-257, 261-265, 269-273, 276-287, 290-312, 316-320, 324-333, 337-341, 345-349, 353-357, 361-365, 369-373, 377-381, 385-389, 393-397, 401-405, 409-413, 417-421, 425-429, 433-437, 441-445, 449-454, 458-463, 467-470, 474-478, 482-487, 491-495, 499-503, 507-518, 525-533, 537-541, 545-549, 553-557, 561-565, 569-573, 577-581, 584-603, 606-694, 701-781, 788-871, 878-900, 903-931, 934-961, 964-981, 988-1005, 1008-1011, 1015-1031, 1034-1045, 1048-1056, 1060-1078, 1081-1088, 1091-1098, 1101-1103, 1106-1113, 1116-1129, 1132-1136, 1140-1153, 1156-1159, 1163-1171, 1174-1176, 1179-1185, 1188-1197, 1200-1215, 1219-1240, 1243-1249, 1252-1267, 1271-1292, 1295-1303, 1306-1319, 1322-1343, 1346-1364, 1367-1368, 1371-1380, 1383-1393, 1396-1397, 1400-1428, 1431-1450, 1453-1465, 1470-1475, 1480-1484, 1489-1494, 1502-1507, 1512-1517, 1522-1541, 1546-1553, 1558-1585, 1590-1595, 1600-1607, 1611-1615, 1619
---------------------------------------------------
TOTAL                  3236   2627    19%

